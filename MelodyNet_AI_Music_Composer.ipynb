{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mJQlveHDrHFb5xQxmWhkNfxbYApNKTYU",
      "authorship_tag": "ABX9TyM/zxxO/iWndGk5vFDVYoEM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhillDev-coder256/MelodyNet-AI-Music-Composer/blob/main/MelodyNet_AI_Music_Composer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwlt9pcWdKam",
        "outputId": "68541b32-cfaa-4c5b-d08f-a3804bdaad9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the path to the zip file and the destination folder\n",
        "zip_file_path = '/content/drive/MyDrive/Lo-Fi Hip Hop MIDIs.zip'\n",
        "extract_to_folder = '/content/drive/MyDrive/Songs'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "Path(extract_to_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_folder)\n",
        "\n",
        "print(f'Files extracted to: {extract_to_folder}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edM1F01xenFh",
        "outputId": "5d1ccbcb-f9ff-4711-c7d8-718a1b2243e8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to: /content/drive/MyDrive/Songs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "songs = []\n",
        "folder = Path('/content/drive/MyDrive/Songs')\n",
        "for file in folder.rglob('*.mid'):\n",
        "  songs.append(file)\n",
        "  print(file)\n",
        "  print(len(songs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmTf8_5Re2Zj",
        "outputId": "53e348c7-1de1-4de0-e775-8e8c96075ad1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Songs/1.mid\n",
            "1\n",
            "/content/drive/MyDrive/Songs/10.mid\n",
            "2\n",
            "/content/drive/MyDrive/Songs/11.mid\n",
            "3\n",
            "/content/drive/MyDrive/Songs/12.mid\n",
            "4\n",
            "/content/drive/MyDrive/Songs/13.mid\n",
            "5\n",
            "/content/drive/MyDrive/Songs/14.mid\n",
            "6\n",
            "/content/drive/MyDrive/Songs/15.mid\n",
            "7\n",
            "/content/drive/MyDrive/Songs/16.mid\n",
            "8\n",
            "/content/drive/MyDrive/Songs/17.mid\n",
            "9\n",
            "/content/drive/MyDrive/Songs/18.mid\n",
            "10\n",
            "/content/drive/MyDrive/Songs/19.mid\n",
            "11\n",
            "/content/drive/MyDrive/Songs/2.mid\n",
            "12\n",
            "/content/drive/MyDrive/Songs/20.mid\n",
            "13\n",
            "/content/drive/MyDrive/Songs/3.mid\n",
            "14\n",
            "/content/drive/MyDrive/Songs/4.mid\n",
            "15\n",
            "/content/drive/MyDrive/Songs/5.mid\n",
            "16\n",
            "/content/drive/MyDrive/Songs/6.mid\n",
            "17\n",
            "/content/drive/MyDrive/Songs/7.mid\n",
            "18\n",
            "/content/drive/MyDrive/Songs/8.mid\n",
            "19\n",
            "/content/drive/MyDrive/Songs/9.mid\n",
            "20\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 1 - C Maj.mid\n",
            "21\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 10 - F Min.mid\n",
            "22\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 11 - A Maj.mid\n",
            "23\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 12 - A Min.mid\n",
            "24\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 13 - A Min.mid\n",
            "25\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 14 - A Min.mid\n",
            "26\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 15 - A Maj.mid\n",
            "27\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 16 - A Maj.mid\n",
            "28\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 17 - A Maj.mid\n",
            "29\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 18 - A Maj.mid\n",
            "30\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 19 - A Min.mid\n",
            "31\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 2 - C Min.mid\n",
            "32\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 20 - A Min.mid\n",
            "33\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 21 - A Min.mid\n",
            "34\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 22 - B Min.mid\n",
            "35\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 3 - D Maj.mid\n",
            "36\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 4 - D Maj.mid\n",
            "37\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 5 - D Min.mid\n",
            "38\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 6 - D Min.mid\n",
            "39\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 7 - E Min.mid\n",
            "40\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 8 - F Maj.mid\n",
            "41\n",
            "/content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 9 - F Min.mid\n",
            "42\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 1 - C Maj.mid\n",
            "43\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 10 - D Maj.mid\n",
            "44\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 11 - E Maj.mid\n",
            "45\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 12 - E Min.mid\n",
            "46\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 13 - E Min.mid\n",
            "47\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 14 - F Min.mid\n",
            "48\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 15 - F Maj.mid\n",
            "49\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 16 - F Maj.mid\n",
            "50\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 17 - G Maj.mid\n",
            "51\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 18 - G Maj.mid\n",
            "52\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 19 - G Maj.mid\n",
            "53\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 2 - C Maj.mid\n",
            "54\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 20 - G Min.mid\n",
            "55\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 21 - A Min.mid\n",
            "56\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 22 - B Min.mid\n",
            "57\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 3 - C Min.mid\n",
            "58\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 4 - D Maj.mid\n",
            "59\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 5 - D Maj.mid\n",
            "60\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 6 - D Min.mid\n",
            "61\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 7 - D Maj.mid\n",
            "62\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 8 - D Maj.mid\n",
            "63\n",
            "/content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 9 - D Maj.mid\n",
            "64\n",
            "/content/drive/MyDrive/Songs/E-Piano Chords MIDI.mid\n",
            "65\n",
            "/content/drive/MyDrive/Songs/E-Piano MIDI (2).mid\n",
            "66\n",
            "/content/drive/MyDrive/Songs/E-Piano MIDI.mid\n",
            "67\n",
            "/content/drive/MyDrive/Songs/Lofi Piano MIDI.mid\n",
            "68\n",
            "/content/drive/MyDrive/Songs/Piano 1 MIDI.mid\n",
            "69\n",
            "/content/drive/MyDrive/Songs/Piano 2 MIDI.mid\n",
            "70\n",
            "/content/drive/MyDrive/Songs/Piano Chords MIDI (2).mid\n",
            "71\n",
            "/content/drive/MyDrive/Songs/Piano Chords MIDI (3).mid\n",
            "72\n",
            "/content/drive/MyDrive/Songs/Piano Chords MIDI.mid\n",
            "73\n",
            "/content/drive/MyDrive/Songs/Piano MIDI (2).mid\n",
            "74\n",
            "/content/drive/MyDrive/Songs/Piano MIDI (3).mid\n",
            "75\n",
            "/content/drive/MyDrive/Songs/Piano MIDI (4).mid\n",
            "76\n",
            "/content/drive/MyDrive/Songs/Piano MIDI (5).mid\n",
            "77\n",
            "/content/drive/MyDrive/Songs/Piano MIDI (6).mid\n",
            "78\n",
            "/content/drive/MyDrive/Songs/Piano MIDI (7).mid\n",
            "79\n",
            "/content/drive/MyDrive/Songs/Piano MIDI (8).mid\n",
            "80\n",
            "/content/drive/MyDrive/Songs/Piano MIDI 1.mid\n",
            "81\n",
            "/content/drive/MyDrive/Songs/Piano MIDI 2.mid\n",
            "82\n",
            "/content/drive/MyDrive/Songs/Piano MIDI.mid\n",
            "83\n",
            "/content/drive/MyDrive/Songs/Rhodes MIDI (2).mid\n",
            "84\n",
            "/content/drive/MyDrive/Songs/Rhodes MIDI (3).mid\n",
            "85\n",
            "/content/drive/MyDrive/Songs/Rhodes MIDI (4).mid\n",
            "86\n",
            "/content/drive/MyDrive/Songs/Rhodes MIDI (5).mid\n",
            "87\n",
            "/content/drive/MyDrive/Songs/Rhodes MIDI (6).mid\n",
            "88\n",
            "/content/drive/MyDrive/Songs/Rhodes MIDI (7).mid\n",
            "89\n",
            "/content/drive/MyDrive/Songs/Rhodes MIDI (8).mid\n",
            "90\n",
            "/content/drive/MyDrive/Songs/Rhodes MIDI (9).mid\n",
            "91\n",
            "/content/drive/MyDrive/Songs/Rhodes MIDI.mid\n",
            "92\n",
            "/content/drive/MyDrive/Songs/merge_from_ofoct.mid\n",
            "93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Get a subset of 1000 songs\n",
        "result =  random.sample([x for x in songs], 90)"
      ],
      "metadata": {
        "id": "RVZFiZkgd37R"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from music21 import converter, instrument, note, chord\n",
        "notes = []\n",
        "for i,file in enumerate(result):\n",
        "    print(f'{i+1}: {file}')\n",
        "    try:\n",
        "      midi = converter.parse(file)\n",
        "      notes_to_parse = None\n",
        "      parts = instrument.partitionByInstrument(midi)\n",
        "      if parts: # file has instrument parts\n",
        "          notes_to_parse = parts.parts[0].recurse()\n",
        "      else: # file has notes in a flat structure\n",
        "          notes_to_parse = midi.flat.notes\n",
        "      for element in notes_to_parse:\n",
        "          if isinstance(element, note.Note):\n",
        "              notes.append(str(element.pitch))\n",
        "          elif isinstance(element, chord.Chord):\n",
        "              notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "    except:\n",
        "      print(f'FAILED: {i+1}: {file}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbwpNA4WeC11",
        "outputId": "b0cd33d5-7acb-43c7-adf9-4a04a316202d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 3 - C Min.mid\n",
            "2: /content/drive/MyDrive/Songs/Piano Chords MIDI.mid\n",
            "3: /content/drive/MyDrive/Songs/5.mid\n",
            "4: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 16 - A Maj.mid\n",
            "5: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 19 - G Maj.mid\n",
            "6: /content/drive/MyDrive/Songs/8.mid\n",
            "7: /content/drive/MyDrive/Songs/Rhodes MIDI (6).mid\n",
            "8: /content/drive/MyDrive/Songs/Rhodes MIDI (3).mid\n",
            "9: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 20 - A Min.mid\n",
            "10: /content/drive/MyDrive/Songs/13.mid\n",
            "11: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 9 - F Min.mid\n",
            "12: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 22 - B Min.mid\n",
            "13: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 6 - D Min.mid\n",
            "14: /content/drive/MyDrive/Songs/Rhodes MIDI (2).mid\n",
            "15: /content/drive/MyDrive/Songs/Piano 1 MIDI.mid\n",
            "16: /content/drive/MyDrive/Songs/15.mid\n",
            "17: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 11 - A Maj.mid\n",
            "18: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 16 - F Maj.mid\n",
            "19: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 6 - D Min.mid\n",
            "20: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 18 - G Maj.mid\n",
            "21: /content/drive/MyDrive/Songs/Piano MIDI 1.mid\n",
            "22: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 17 - A Maj.mid\n",
            "23: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 4 - D Maj.mid\n",
            "24: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 20 - G Min.mid\n",
            "25: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 19 - A Min.mid\n",
            "26: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 7 - D Maj.mid\n",
            "27: /content/drive/MyDrive/Songs/Piano MIDI (5).mid\n",
            "28: /content/drive/MyDrive/Songs/9.mid\n",
            "29: /content/drive/MyDrive/Songs/Lofi Piano MIDI.mid\n",
            "30: /content/drive/MyDrive/Songs/Piano MIDI (6).mid\n",
            "31: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 13 - A Min.mid\n",
            "32: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 1 - C Maj.mid\n",
            "33: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 5 - D Min.mid\n",
            "34: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 18 - A Maj.mid\n",
            "35: /content/drive/MyDrive/Songs/Piano Chords MIDI (3).mid\n",
            "36: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 8 - F Maj.mid\n",
            "37: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 21 - A Min.mid\n",
            "38: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 8 - D Maj.mid\n",
            "39: /content/drive/MyDrive/Songs/Piano MIDI (8).mid\n",
            "40: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 3 - D Maj.mid\n",
            "41: /content/drive/MyDrive/Songs/10.mid\n",
            "42: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 22 - B Min.mid\n",
            "43: /content/drive/MyDrive/Songs/E-Piano MIDI (2).mid\n",
            "44: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 15 - A Maj.mid\n",
            "45: /content/drive/MyDrive/Songs/Piano MIDI (3).mid\n",
            "46: /content/drive/MyDrive/Songs/Piano MIDI.mid\n",
            "47: /content/drive/MyDrive/Songs/E-Piano MIDI.mid\n",
            "48: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 14 - A Min.mid\n",
            "49: /content/drive/MyDrive/Songs/11.mid\n",
            "50: /content/drive/MyDrive/Songs/6.mid\n",
            "51: /content/drive/MyDrive/Songs/16.mid\n",
            "52: /content/drive/MyDrive/Songs/19.mid\n",
            "53: /content/drive/MyDrive/Songs/Piano MIDI (2).mid\n",
            "54: /content/drive/MyDrive/Songs/Piano 2 MIDI.mid\n",
            "55: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 10 - D Maj.mid\n",
            "56: /content/drive/MyDrive/Songs/Rhodes MIDI (5).mid\n",
            "57: /content/drive/MyDrive/Songs/Rhodes MIDI (8).mid\n",
            "58: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 9 - D Maj.mid\n",
            "59: /content/drive/MyDrive/Songs/20.mid\n",
            "60: /content/drive/MyDrive/Songs/17.mid\n",
            "61: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 4 - D Maj.mid\n",
            "62: /content/drive/MyDrive/Songs/Piano MIDI (4).mid\n",
            "63: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 2 - C Maj.mid\n",
            "64: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 14 - F Min.mid\n",
            "65: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 17 - G Maj.mid\n",
            "66: /content/drive/MyDrive/Songs/Rhodes MIDI (4).mid\n",
            "67: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 12 - A Min.mid\n",
            "68: /content/drive/MyDrive/Songs/Piano Chords MIDI (2).mid\n",
            "69: /content/drive/MyDrive/Songs/1.mid\n",
            "70: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 11 - E Maj.mid\n",
            "71: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 7 - E Min.mid\n",
            "72: /content/drive/MyDrive/Songs/4.mid\n",
            "73: /content/drive/MyDrive/Songs/Piano MIDI 2.mid\n",
            "74: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 15 - F Maj.mid\n",
            "75: /content/drive/MyDrive/Songs/14.mid\n",
            "76: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 2 - C Min.mid\n",
            "77: /content/drive/MyDrive/Songs/Piano MIDI (7).mid\n",
            "78: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 21 - A Min.mid\n",
            "79: /content/drive/MyDrive/Songs/18.mid\n",
            "80: /content/drive/MyDrive/Songs/E-Piano Chords MIDI.mid\n",
            "81: /content/drive/MyDrive/Songs/2.mid\n",
            "82: /content/drive/MyDrive/Songs/3.mid\n",
            "83: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 12 - E Min.mid\n",
            "84: /content/drive/MyDrive/Songs/merge_from_ofoct.mid\n",
            "85: /content/drive/MyDrive/Songs/Cymatics - Eternity MIDI 1 - C Maj.mid\n",
            "86: /content/drive/MyDrive/Songs/Cymatics - Lofi MIDI 5 - D Maj.mid\n",
            "87: /content/drive/MyDrive/Songs/Rhodes MIDI (7).mid\n",
            "88: /content/drive/MyDrive/Songs/7.mid\n",
            "89: /content/drive/MyDrive/Songs/12.mid\n",
            "90: /content/drive/MyDrive/Songs/Rhodes MIDI.mid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "# from keras.utils import np_utils # Remove this line as np_utils is no longer available\n",
        "# from keras.utils import to_categorical # Use to_categorical for one-hot encoding if needed\n",
        "from tensorflow.keras.utils import to_categorical  # Correct import for to_categorical\n",
        "\n",
        "# Save the notes to a file\n",
        "with open('notes', 'wb') as filepath:\n",
        "  pickle.dump(notes, filepath)"
      ],
      "metadata": {
        "id": "Wcns6Oegfhc2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequences(notes, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 32\n",
        "\n",
        "    # Get all unique pitchnames\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    numPitches = len(pitchnames)\n",
        "\n",
        "    # Create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # Create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # Reshape the input into a format compatible with LSTM layers\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # Normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    # One-hot encode the output\n",
        "    network_output = to_categorical(network_output, num_classes=n_vocab)\n",
        "\n",
        "    return network_input, network_output\n",
        "\n",
        "# Example usage\n",
        "# Replace 'notes' with your actual list of notes\n",
        "n_vocab = len(set(notes))\n",
        "network_input, network_output = prepare_sequences(notes, n_vocab)"
      ],
      "metadata": {
        "id": "vrIoY36kfs0l"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def oversample(network_input, network_output, sequence_length=15):\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # Flatten network_input from (n_patterns, sequence_length, 1) to (n_patterns, sequence_length)\n",
        "    network_input_flattened = network_input.reshape(n_patterns, sequence_length)\n",
        "\n",
        "    # Create a DataFrame from the two matrices\n",
        "    new_df = pd.concat([pd.DataFrame(network_input_flattened), pd.DataFrame(network_output)], axis=1)\n",
        "\n",
        "    # Rename the columns to numbers and Notes\n",
        "    new_df.columns = [x for x in range(sequence_length)] + ['Notes']\n",
        "\n",
        "    print(new_df.tail(20))\n",
        "    print('###################################################')\n",
        "    print(f'Distribution of notes in the pre-oversampled DataFrame: {new_df[\"Notes\"].value_counts()}')\n",
        "\n",
        "    # Oversampling\n",
        "    oversampled_df = new_df.copy()\n",
        "    max_class_size = 700\n",
        "    print('Size of biggest class: ', max_class_size)\n",
        "\n",
        "    class_subsets = [oversampled_df.query('Notes == ' + str(i)) for i in range(len(new_df[\"Notes\"].unique()))]\n",
        "\n",
        "    for i in range(len(new_df['Notes'].unique())):\n",
        "        try:\n",
        "            class_subsets[i] = class_subsets[i].sample(max_class_size, random_state=42, replace=True)\n",
        "        except:\n",
        "            print(i)\n",
        "\n",
        "    oversampled_df = pd.concat(class_subsets, axis=0).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    print('###################################################')\n",
        "    print(f'Distribution of notes in the oversampled DataFrame: {oversampled_df[\"Notes\"].value_counts()}')\n",
        "\n",
        "    # Get a sample from the oversampled DataFrame\n",
        "    sampled_df = oversampled_df.sample(n_patterns, replace=True)\n",
        "\n",
        "    print('###################################################')\n",
        "    print(f'Distribution of notes in the oversampled post-sampled DataFrame: {sampled_df[\"Notes\"].value_counts()}')\n",
        "\n",
        "    # Convert the training columns back to a 3D array\n",
        "    network_in = sampled_df[[x for x in range(sequence_length)]]\n",
        "    network_in = np.array(network_in)\n",
        "    network_in = np.reshape(network_in, (n_patterns, sequence_length, 1))\n",
        "    network_in = network_in / len(set(new_df['Notes']))  # Normalization\n",
        "    print(network_in.shape)\n",
        "\n",
        "    # Converts the target column into a OneHot encoded matrix\n",
        "    network_out = pd.get_dummies(sampled_df['Notes'])\n",
        "    print(network_out.shape)\n",
        "\n",
        "    return network_in, network_out\n",
        "\n",
        "# Example variables\n",
        "# Make sure these are defined correctly in your actual environment\n",
        "networkInput = np.random.randint(0, 10, size=(100, 15, 1))  # Example input\n",
        "networkOutput = np.random.randint(0, 10, size=(100, 1))     # Example output\n",
        "seqLength = 15\n",
        "\n",
        "# Call the oversample function\n",
        "networkInputShaped, networkOutputShaped = oversample(networkInput, networkOutput, sequence_length=seqLength)\n",
        "networkOutputShaped = to_categorical(networkOutputShaped)\n",
        "print(networkInputShaped.shape)\n",
        "print(networkOutputShaped.shape)\n",
        "print(networkOutputShaped)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLvsIBRBh9E9",
        "outputId": "b431973b-53a4-4b33-ff40-6ef8114faba6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  Notes\n",
            "80  9  0  2  0  3  1  2  4  2  6   9   3   9   3   7      7\n",
            "81  4  4  9  1  1  0  3  9  6  7   0   3   4   3   9      9\n",
            "82  5  5  3  3  8  7  8  6  8  6   5   7   4   3   0      5\n",
            "83  8  2  2  8  0  0  2  8  9  2   5   0   4   6   5      1\n",
            "84  6  4  4  9  3  2  2  3  8  7   1   3   2   8   5      6\n",
            "85  3  6  7  7  6  9  7  8  3  2   6   9   9   9   1      3\n",
            "86  3  9  3  2  5  2  7  9  2  5   4   8   9   1   0      2\n",
            "87  6  5  2  2  7  8  3  1  8  2   6   6   6   5   3      1\n",
            "88  0  7  1  5  7  5  8  8  5  4   5   2   7   1   5      3\n",
            "89  4  7  2  1  6  2  2  3  4  3   8   4   2   7   4      3\n",
            "90  4  7  1  3  4  7  7  9  7  6   0   3   1   6   3      0\n",
            "91  3  1  0  2  1  5  4  0  4  7   6   3   8   8   5      1\n",
            "92  0  6  5  3  1  5  9  7  7  8   5   6   2   9   7      4\n",
            "93  0  9  6  2  5  2  3  0  3  6   3   1   6   5   8      2\n",
            "94  6  6  9  4  5  8  1  1  3  7   3   9   6   0   5      3\n",
            "95  1  2  2  5  6  4  7  9  9  8   9   0   5   8   6      7\n",
            "96  2  1  6  2  9  2  6  9  2  3   7   7   4   2   8      8\n",
            "97  4  2  6  3  5  2  0  8  6  3   2   2   8   8   8      1\n",
            "98  3  4  4  7  9  8  8  6  4  3   1   5   8   7   4      5\n",
            "99  0  0  8  1  2  6  5  8  7  3   6   9   4   2   2      4\n",
            "###################################################\n",
            "Distribution of notes in the pre-oversampled DataFrame: Notes\n",
            "5    14\n",
            "0    12\n",
            "8    12\n",
            "1    12\n",
            "3    11\n",
            "7    10\n",
            "4     8\n",
            "6     8\n",
            "9     7\n",
            "2     6\n",
            "Name: count, dtype: int64\n",
            "Size of biggest class:  700\n",
            "###################################################\n",
            "Distribution of notes in the oversampled DataFrame: Notes\n",
            "9    700\n",
            "4    700\n",
            "2    700\n",
            "0    700\n",
            "6    700\n",
            "8    700\n",
            "7    700\n",
            "3    700\n",
            "1    700\n",
            "5    700\n",
            "Name: count, dtype: int64\n",
            "###################################################\n",
            "Distribution of notes in the oversampled post-sampled DataFrame: Notes\n",
            "2    14\n",
            "9    14\n",
            "1    13\n",
            "5    12\n",
            "0    11\n",
            "3    10\n",
            "4     8\n",
            "7     8\n",
            "6     7\n",
            "8     3\n",
            "Name: count, dtype: int64\n",
            "(100, 15, 1)\n",
            "(100, 10)\n",
            "(100, 15, 1)\n",
            "(100, 10, 2)\n",
            "[[[1. 0.]\n",
            "  [0. 1.]\n",
            "  [1. 0.]\n",
            "  ...\n",
            "  [1. 0.]\n",
            "  [1. 0.]\n",
            "  [1. 0.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 0.]\n",
            "  [1. 0.]\n",
            "  ...\n",
            "  [1. 0.]\n",
            "  [1. 0.]\n",
            "  [1. 0.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 0.]\n",
            "  [0. 1.]\n",
            "  ...\n",
            "  [1. 0.]\n",
            "  [1. 0.]\n",
            "  [1. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 0.]\n",
            "  [1. 0.]\n",
            "  ...\n",
            "  [1. 0.]\n",
            "  [1. 0.]\n",
            "  [1. 0.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 0.]\n",
            "  [1. 0.]\n",
            "  ...\n",
            "  [1. 0.]\n",
            "  [1. 0.]\n",
            "  [1. 0.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 0.]\n",
            "  [1. 0.]\n",
            "  ...\n",
            "  [1. 0.]\n",
            "  [1. 0.]\n",
            "  [0. 1.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we are done processing our songs, we now move on to training our model. But first, to recap what we have done so far, we have:\n",
        "\n",
        "Collected our MIDI files\n",
        "Loaded the MIDI files into memory\n",
        "Transformed the MIDI files into a list of sequenced notes/chords\n",
        "Transformed the list into a (n, m, 1) matrix and (n, 1) vector (n = 99968, m = 32)\n",
        "For our model, we will be using an LSTM network to predict the 33rd note/chord taking into account our previous 32 notes/chords. We will be using LSTMs because of it’s feedback connections. They are very useful when dealing with sequenced data.\n",
        "\n",
        "LSTMs are a type of recurrent neural network, but are different from other networks. Other networks repeat the module each time the entry receives new information. However, the LSTM will remember the problem longer and has a string-like structure to repeat the module.\n",
        "\n",
        "LSTM are basically units as depicted:\n",
        "\n",
        "\n",
        "Image taken from https://en.wikipedia.org/wiki/Long_short-term_memory\n",
        "An LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. Let’s take a look at what this means, and why LSTMs are good for sequential data.\n",
        "\n",
        "The job of the forget gate is to decide whether to keep or forget the information. Only the information that comes from previously hidden layers and the current input is kept with the sigmoid function. Any value closer to one will remain, and any value closer to zero will disappear.\n",
        "\n",
        "The input gate helps to update the status of the cells. The current input and previous state information is passed through the sigmoid function, which will update the value by multiplying it by 0 and 1. Similarly, to regulate the network, the data also goes through the tanh function. Now, the output of the sigmoid is multiplied by the output of tanh. The output of the sigmoid will identify valuable information to avoid the output of tanh.\n",
        "\n",
        "The output gate determines the value of the next hidden state. To find the hidden state information, we need to multiply the sigmoid output by the tanh output. Now the new hidden state and the new cell state will travel to the next step.\n",
        "\n",
        "When training an LSTM network it is requieres to use a GPU. In my case, I used Google Colab Pro when training the neural network. Google Colab has a set limit of compute units we can use when training with GPUs. You can use the free GPU for a couple of dozen of epochs."
      ],
      "metadata": {
        "id": "c129HHyKi5D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "RZDehNHTjM_M"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pitchnames = sorted(set(notes))  # Assuming notes is defined\n",
        "# numPitches = len(pitchnames)"
      ],
      "metadata": {
        "id": "Ukb9UNVkjkf7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the sequence length and number of features\n",
        "sequence_length = 32  # Update as needed\n",
        "num_features = networkInputShaped.shape[2]  # Ensure this matches your input features\n",
        "\n",
        "# Define numPitches based on your data\n",
        "pitchnames = sorted(set(notes))  # Replace notes with your actual notes list\n",
        "numPitches = len(pitchnames)  # Ensure this matches the number of classes\n",
        "\n",
        "# Ensure networkOutputShaped is one-hot encoded correctly\n",
        "networkOutputShaped = to_categorical(networkOutput, num_classes=numPitches)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(512, input_shape=(sequence_length, num_features), return_sequences=True))\n",
        "model.add(Dense(256))\n",
        "model.add(Dense(256))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dense(256))\n",
        "model.add(LSTM(512))\n",
        "model.add(Dense(numPitches))  # Match this to the number of classes\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary to verify the shape and parameters\n",
        "print(model.summary())\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(networkInputShaped, networkOutputShaped, epochs=num_epochs, batch_size=64, callbacks=callbacks_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fFOwrvcVi758",
        "outputId": "9360e967-98db-49a6-80ce-f8e714899577"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_21 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_22 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_23 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718ms/step - accuracy: 0.0150 - loss: 5.4846 \n",
            "Epoch 1: loss improved from inf to 5.47057, saving model to weights-improvement-01-5.4706-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.0200 - loss: 5.4799  \n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677ms/step - accuracy: 0.1147 - loss: 4.5954\n",
            "Epoch 2: loss improved from 5.47057 to 4.23961, saving model to weights-improvement-02-4.2396-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 966ms/step - accuracy: 0.1165 - loss: 4.4768\n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1609 - loss: 3.4789\n",
            "Epoch 3: loss improved from 4.23961 to 3.39187, saving model to weights-improvement-03-3.3919-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1573 - loss: 3.4499\n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817ms/step - accuracy: 0.0791 - loss: 2.9596\n",
            "Epoch 4: loss improved from 3.39187 to 2.89603, saving model to weights-improvement-04-2.8960-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.0794 - loss: 2.9384   \n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - accuracy: 0.0769 - loss: 2.6053\n",
            "Epoch 5: loss improved from 2.89603 to 2.58166, saving model to weights-improvement-05-2.5817-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 936ms/step - accuracy: 0.0712 - loss: 2.5974\n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713ms/step - accuracy: 0.1203 - loss: 2.4903\n",
            "Epoch 6: loss improved from 2.58166 to 2.52747, saving model to weights-improvement-06-2.5275-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 943ms/step - accuracy: 0.1135 - loss: 2.5027\n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - accuracy: 0.1431 - loss: 2.4406\n",
            "Epoch 7: loss improved from 2.52747 to 2.43517, saving model to weights-improvement-07-2.4352-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1388 - loss: 2.4388   \n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1509 - loss: 2.3790\n",
            "Epoch 8: loss improved from 2.43517 to 2.39137, saving model to weights-improvement-08-2.3914-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1440 - loss: 2.3831\n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966ms/step - accuracy: 0.1175 - loss: 2.3803\n",
            "Epoch 9: loss did not improve from 2.39137\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 985ms/step - accuracy: 0.1150 - loss: 2.3840\n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step - accuracy: 0.1409 - loss: 2.3627\n",
            "Epoch 10: loss improved from 2.39137 to 2.38144, saving model to weights-improvement-10-2.3814-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 959ms/step - accuracy: 0.1306 - loss: 2.3689\n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686ms/step - accuracy: 0.1303 - loss: 2.3721\n",
            "Epoch 11: loss improved from 2.38144 to 2.36791, saving model to weights-improvement-11-2.3679-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 934ms/step - accuracy: 0.1269 - loss: 2.3707\n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step - accuracy: 0.1381 - loss: 2.3442\n",
            "Epoch 12: loss did not improve from 2.36791\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 700ms/step - accuracy: 0.1321 - loss: 2.3522\n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0662 - loss: 2.4502\n",
            "Epoch 13: loss did not improve from 2.36791\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.0675 - loss: 2.4558\n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0869 - loss: 2.3891\n",
            "Epoch 14: loss did not improve from 2.36791\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.0846 - loss: 2.3914\n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695ms/step - accuracy: 0.1353 - loss: 2.3610\n",
            "Epoch 15: loss did not improve from 2.36791\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.1335 - loss: 2.3635\n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - accuracy: 0.1659 - loss: 2.3033\n",
            "Epoch 16: loss improved from 2.36791 to 2.31158, saving model to weights-improvement-16-2.3116-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 907ms/step - accuracy: 0.1640 - loss: 2.3061\n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step - accuracy: 0.1225 - loss: 2.3659\n",
            "Epoch 17: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 700ms/step - accuracy: 0.1217 - loss: 2.3619\n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1303 - loss: 2.3351\n",
            "Epoch 18: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1269 - loss: 2.3374\n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1403 - loss: 2.3534\n",
            "Epoch 19: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1402 - loss: 2.3517\n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676ms/step - accuracy: 0.0997 - loss: 2.3405\n",
            "Epoch 20: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 685ms/step - accuracy: 0.0965 - loss: 2.3378\n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - accuracy: 0.1253 - loss: 2.3279\n",
            "Epoch 21: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 711ms/step - accuracy: 0.1202 - loss: 2.3455\n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675ms/step - accuracy: 0.1303 - loss: 2.3404\n",
            "Epoch 22: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 687ms/step - accuracy: 0.1269 - loss: 2.3444\n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0947 - loss: 2.3393\n",
            "Epoch 23: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.0898 - loss: 2.3405\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805ms/step - accuracy: 0.1431 - loss: 2.3472\n",
            "Epoch 24: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 814ms/step - accuracy: 0.1388 - loss: 2.3497\n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step - accuracy: 0.1325 - loss: 2.3934\n",
            "Epoch 25: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 702ms/step - accuracy: 0.1350 - loss: 2.3866\n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step - accuracy: 0.1559 - loss: 2.3490\n",
            "Epoch 26: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 675ms/step - accuracy: 0.1506 - loss: 2.3582\n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step - accuracy: 0.1253 - loss: 2.3433\n",
            "Epoch 27: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 698ms/step - accuracy: 0.1202 - loss: 2.3540\n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0662 - loss: 2.3342\n",
            "Epoch 28: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.0675 - loss: 2.3363\n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683ms/step - accuracy: 0.1303 - loss: 2.3291\n",
            "Epoch 29: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 693ms/step - accuracy: 0.1269 - loss: 2.3312\n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - accuracy: 0.1097 - loss: 2.3417\n",
            "Epoch 30: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 702ms/step - accuracy: 0.1098 - loss: 2.3468\n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684ms/step - accuracy: 0.1125 - loss: 2.3232\n",
            "Epoch 31: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692ms/step - accuracy: 0.1083 - loss: 2.3250\n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996ms/step - accuracy: 0.1303 - loss: 2.3031\n",
            "Epoch 32: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1269 - loss: 2.3084   \n",
            "Epoch 33/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1075 - loss: 2.3294\n",
            "Epoch 33: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1017 - loss: 2.3393\n",
            "Epoch 34/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.1047 - loss: 2.3566\n",
            "Epoch 34: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 705ms/step - accuracy: 0.1031 - loss: 2.3521\n",
            "Epoch 35/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688ms/step - accuracy: 0.1303 - loss: 2.3135\n",
            "Epoch 35: loss did not improve from 2.31158\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 697ms/step - accuracy: 0.1269 - loss: 2.3132\n",
            "Epoch 36/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848ms/step - accuracy: 0.1353 - loss: 2.2857\n",
            "Epoch 36: loss improved from 2.31158 to 2.29014, saving model to weights-improvement-36-2.2901-bigger_1.keras\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1335 - loss: 2.2872   \n",
            "Epoch 37/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0869 - loss: 2.3357\n",
            "Epoch 37: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.0846 - loss: 2.3473\n",
            "Epoch 38/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step - accuracy: 0.1353 - loss: 2.4010\n",
            "Epoch 38: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 699ms/step - accuracy: 0.1335 - loss: 2.4008\n",
            "Epoch 39/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - accuracy: 0.1303 - loss: 2.3055\n",
            "Epoch 39: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 688ms/step - accuracy: 0.1269 - loss: 2.3122\n",
            "Epoch 40/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - accuracy: 0.1481 - loss: 2.3139\n",
            "Epoch 40: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 691ms/step - accuracy: 0.1454 - loss: 2.3180\n",
            "Epoch 41/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.1175 - loss: 2.3133\n",
            "Epoch 41: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 701ms/step - accuracy: 0.1150 - loss: 2.3207\n",
            "Epoch 42/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994ms/step - accuracy: 0.0897 - loss: 2.3835\n",
            "Epoch 42: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.0831 - loss: 2.3833   \n",
            "Epoch 43/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1459 - loss: 2.3185\n",
            "Epoch 43: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1373 - loss: 2.3258\n",
            "Epoch 44/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694ms/step - accuracy: 0.1175 - loss: 2.3359\n",
            "Epoch 44: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703ms/step - accuracy: 0.1150 - loss: 2.3363\n",
            "Epoch 45/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671ms/step - accuracy: 0.1403 - loss: 2.3138\n",
            "Epoch 45: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 684ms/step - accuracy: 0.1402 - loss: 2.3166\n",
            "Epoch 46/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step - accuracy: 0.0969 - loss: 2.3104\n",
            "Epoch 46: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 697ms/step - accuracy: 0.0979 - loss: 2.3108\n",
            "Epoch 47/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1125 - loss: 2.3021\n",
            "Epoch 47: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1083 - loss: 2.3081\n",
            "Epoch 48/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1481 - loss: 2.3188\n",
            "Epoch 48: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1454 - loss: 2.3218\n",
            "Epoch 49/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - accuracy: 0.1147 - loss: 2.3032\n",
            "Epoch 49: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676ms/step - accuracy: 0.1165 - loss: 2.3082\n",
            "Epoch 50/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684ms/step - accuracy: 0.1609 - loss: 2.2962\n",
            "Epoch 50: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692ms/step - accuracy: 0.1573 - loss: 2.3016\n",
            "Epoch 51/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717ms/step - accuracy: 0.1275 - loss: 2.3103\n",
            "Epoch 51: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725ms/step - accuracy: 0.1283 - loss: 2.3148\n",
            "Epoch 52/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684ms/step - accuracy: 0.0969 - loss: 2.3155\n",
            "Epoch 52: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692ms/step - accuracy: 0.0979 - loss: 2.3223\n",
            "Epoch 53/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step - accuracy: 0.1303 - loss: 2.3133\n",
            "Epoch 53: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 683ms/step - accuracy: 0.1269 - loss: 2.3185\n",
            "Epoch 54/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0997 - loss: 2.3755\n",
            "Epoch 54: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.0965 - loss: 2.3715\n",
            "Epoch 55/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step - accuracy: 0.1175 - loss: 2.3067\n",
            "Epoch 55: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 701ms/step - accuracy: 0.1150 - loss: 2.3102\n",
            "Epoch 56/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813ms/step - accuracy: 0.1303 - loss: 2.3156\n",
            "Epoch 56: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 828ms/step - accuracy: 0.1269 - loss: 2.3143\n",
            "Epoch 57/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - accuracy: 0.1303 - loss: 2.3201\n",
            "Epoch 57: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 690ms/step - accuracy: 0.1269 - loss: 2.3186\n",
            "Epoch 58/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991ms/step - accuracy: 0.1153 - loss: 2.3595\n",
            "Epoch 58: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1069 - loss: 2.3775   \n",
            "Epoch 59/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1125 - loss: 2.3657\n",
            "Epoch 59: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1083 - loss: 2.3727\n",
            "Epoch 60/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705ms/step - accuracy: 0.1637 - loss: 2.3246\n",
            "Epoch 60: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 717ms/step - accuracy: 0.1558 - loss: 2.3270\n",
            "Epoch 61/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719ms/step - accuracy: 0.1097 - loss: 2.3023\n",
            "Epoch 61: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 728ms/step - accuracy: 0.1098 - loss: 2.3014\n",
            "Epoch 62/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722ms/step - accuracy: 0.1481 - loss: 2.2709\n",
            "Epoch 62: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 729ms/step - accuracy: 0.1454 - loss: 2.2790\n",
            "Epoch 63/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.0791 - loss: 2.3159\n",
            "Epoch 63: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 740ms/step - accuracy: 0.0794 - loss: 2.3261\n",
            "Epoch 64/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1381 - loss: 2.3181\n",
            "Epoch 64: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.1321 - loss: 2.3238\n",
            "Epoch 65/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881ms/step - accuracy: 0.0812 - loss: 2.3482\n",
            "Epoch 65: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 893ms/step - accuracy: 0.0875 - loss: 2.3450\n",
            "Epoch 66/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770ms/step - accuracy: 0.1097 - loss: 2.3331\n",
            "Epoch 66: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 780ms/step - accuracy: 0.1098 - loss: 2.3360\n",
            "Epoch 67/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719ms/step - accuracy: 0.1225 - loss: 2.3041\n",
            "Epoch 67: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 732ms/step - accuracy: 0.1217 - loss: 2.3087\n",
            "Epoch 68/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - accuracy: 0.1331 - loss: 2.2945\n",
            "Epoch 68: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714ms/step - accuracy: 0.1254 - loss: 2.2990\n",
            "Epoch 69/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step - accuracy: 0.1047 - loss: 2.3299\n",
            "Epoch 69: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 700ms/step - accuracy: 0.1031 - loss: 2.3276\n",
            "Epoch 70/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804ms/step - accuracy: 0.1453 - loss: 2.2946\n",
            "Epoch 70: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 815ms/step - accuracy: 0.1469 - loss: 2.2938\n",
            "Epoch 71/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1247 - loss: 2.3262\n",
            "Epoch 71: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.1298 - loss: 2.3220\n",
            "Epoch 72/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691ms/step - accuracy: 0.1175 - loss: 2.3153\n",
            "Epoch 72: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 698ms/step - accuracy: 0.1150 - loss: 2.3218\n",
            "Epoch 73/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - accuracy: 0.1125 - loss: 2.3099\n",
            "Epoch 73: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 722ms/step - accuracy: 0.1083 - loss: 2.3168\n",
            "Epoch 74/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703ms/step - accuracy: 0.0869 - loss: 2.3303\n",
            "Epoch 74: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716ms/step - accuracy: 0.0846 - loss: 2.3303\n",
            "Epoch 75/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1481 - loss: 2.2936\n",
            "Epoch 75: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1454 - loss: 2.2947\n",
            "Epoch 76/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796ms/step - accuracy: 0.0819 - loss: 2.3325\n",
            "Epoch 76: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 805ms/step - accuracy: 0.0779 - loss: 2.3423\n",
            "Epoch 77/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924ms/step - accuracy: 0.0869 - loss: 2.3180\n",
            "Epoch 77: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 939ms/step - accuracy: 0.0846 - loss: 2.3188\n",
            "Epoch 78/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721ms/step - accuracy: 0.1381 - loss: 2.2776\n",
            "Epoch 78: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 731ms/step - accuracy: 0.1321 - loss: 2.2835\n",
            "Epoch 79/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906ms/step - accuracy: 0.1481 - loss: 2.2852\n",
            "Epoch 79: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 916ms/step - accuracy: 0.1454 - loss: 2.2887\n",
            "Epoch 80/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1459 - loss: 2.2786\n",
            "Epoch 80: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1373 - loss: 2.2850\n",
            "Epoch 81/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777ms/step - accuracy: 0.1353 - loss: 2.3048\n",
            "Epoch 81: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 790ms/step - accuracy: 0.1335 - loss: 2.3037\n",
            "Epoch 82/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - accuracy: 0.1403 - loss: 2.3038\n",
            "Epoch 82: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722ms/step - accuracy: 0.1402 - loss: 2.3067\n",
            "Epoch 83/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733ms/step - accuracy: 0.0613 - loss: 2.3262\n",
            "Epoch 83: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 742ms/step - accuracy: 0.0608 - loss: 2.3289\n",
            "Epoch 84/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1125 - loss: 2.5189\n",
            "Epoch 84: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1083 - loss: 2.5841\n",
            "Epoch 85/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1225 - loss: 2.7803\n",
            "Epoch 85: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1217 - loss: 2.7497\n",
            "Epoch 86/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731ms/step - accuracy: 0.1353 - loss: 2.3466\n",
            "Epoch 86: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 740ms/step - accuracy: 0.1335 - loss: 2.3459\n",
            "Epoch 87/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713ms/step - accuracy: 0.1403 - loss: 2.2967\n",
            "Epoch 87: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 721ms/step - accuracy: 0.1402 - loss: 2.2980\n",
            "Epoch 88/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717ms/step - accuracy: 0.1538 - loss: 2.2947\n",
            "Epoch 88: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 726ms/step - accuracy: 0.1425 - loss: 2.3029\n",
            "Epoch 89/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727ms/step - accuracy: 0.1303 - loss: 2.2845\n",
            "Epoch 89: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 736ms/step - accuracy: 0.1269 - loss: 2.2958\n",
            "Epoch 90/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1303 - loss: 2.3194\n",
            "Epoch 90: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1269 - loss: 2.3206\n",
            "Epoch 91/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.1253 - loss: 2.3182\n",
            "Epoch 91: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 743ms/step - accuracy: 0.1202 - loss: 2.3213\n",
            "Epoch 92/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776ms/step - accuracy: 0.1431 - loss: 2.3112\n",
            "Epoch 92: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 784ms/step - accuracy: 0.1388 - loss: 2.3134\n",
            "Epoch 93/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738ms/step - accuracy: 0.1409 - loss: 2.3391\n",
            "Epoch 93: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 747ms/step - accuracy: 0.1306 - loss: 2.3485\n",
            "Epoch 94/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948ms/step - accuracy: 0.1203 - loss: 2.3011\n",
            "Epoch 94: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 964ms/step - accuracy: 0.1135 - loss: 2.3067\n",
            "Epoch 95/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0741 - loss: 2.2979\n",
            "Epoch 95: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.0727 - loss: 2.3021\n",
            "Epoch 96/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.0869 - loss: 2.2979\n",
            "Epoch 96: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 775ms/step - accuracy: 0.0846 - loss: 2.3016\n",
            "Epoch 97/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937ms/step - accuracy: 0.0869 - loss: 2.3209\n",
            "Epoch 97: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 951ms/step - accuracy: 0.0846 - loss: 2.3215\n",
            "Epoch 98/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781ms/step - accuracy: 0.1375 - loss: 2.3149\n",
            "Epoch 98: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 790ms/step - accuracy: 0.1417 - loss: 2.3144\n",
            "Epoch 99/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1225 - loss: 2.2949\n",
            "Epoch 99: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.1217 - loss: 2.2958\n",
            "Epoch 100/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829ms/step - accuracy: 0.1097 - loss: 2.2848\n",
            "Epoch 100: loss did not improve from 2.29014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 838ms/step - accuracy: 0.1098 - loss: 2.2880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do we do when we’re done training our network? We choose a random number from 0 to the length of the network input, this will be the index of the row in the training matrix which we will use to make our predictions. We take this sequence of 32 notes/chords as starting point to make a prediction of 1 note. After this, we do this (n — 1) more times (n being 500 in this case). In every prediction we move a window of 32 notes/chords one element to the right. In other words, in the second prediction, once we have predicted one note/chord, we eliminate the first note, and our first prediction becomes the last note/chord in the sequence of length 32. The following images show the previously explained code"
      ],
      "metadata": {
        "id": "fkXFN8Vbl1c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pretty_midi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMkMFTOgnfdl",
        "outputId": "4ea8b8f1-e30d-467e-d50d-d8118557a3a7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.26.4)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Collecting packaging~=23.1 (from mido>=1.1.16->pretty_midi)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Downloading mido-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592288 sha256=c6647d2972b47579e2cab9150cb89357179433d654bb1645d7a9009f7d4da35a\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: packaging, mido, pretty_midi\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "Successfully installed mido-1.3.2 packaging-23.2 pretty_midi-0.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pretty_midi\n",
        "import os\n",
        "\n",
        "def load_notes_from_midi(directory):\n",
        "    all_notes = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.mid'):\n",
        "            midi_path = os.path.join(directory, filename)\n",
        "            midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
        "            for instrument in midi_data.instruments:\n",
        "                for note in instrument.notes:\n",
        "                    all_notes.append(note.pitch)  # Use note.name if you prefer note names\n",
        "    return all_notes\n",
        "\n",
        "# Load all notes from the /Songs directory\n",
        "directory = '/content/drive/MyDrive/Songs'  # Replace with the actual path to your Songs directory\n",
        "allNotes = load_notes_from_midi(directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7oFwCaUnMMV",
        "outputId": "38ab7375-244a-4f7c-96a3-ffd0264faf24"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    # Selects a random row from the network_input\n",
        "    start = numpy.random.randint(0, len(network_input)-1)\n",
        "    print(f'start: {start}')\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    # Random row from network_input\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        # Reshapes pattern into a vector\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        # Standarizes pattern\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        # Predicts the next note\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        # Outputs a OneHot encoded vector, so this picks the columns\n",
        "        # with the highest probability\n",
        "        index = numpy.argmax(prediction)\n",
        "        # Maps the note to its respective index\n",
        "        result = int_to_note[index]\n",
        "        # Appends the note to the prediction_output\n",
        "        prediction_output.append(result)\n",
        "\n",
        "        # Adds the predicted note to the pattern\n",
        "        pattern = numpy.append(pattern,index)\n",
        "        # Slices the array so that it contains the predicted note\n",
        "        # eliminating the first from the array, so the model can\n",
        "        # have a sequence\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output\n",
        "\n",
        "n_vocab = len(set(allNotes))\n",
        "pitchnames = sorted(set(item for item in allNotes))\n",
        "prediction_output = generate_notes(model, networkInputShaped, pitchnames, n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vu3CfT7mECa",
        "outputId": "ec829660-20c5-49b6-f066-bad4c4543502"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With that, we’ve generated our output sequence of 500 notes, that looks like this"
      ],
      "metadata": {
        "id": "yuTXpKN1mIgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we turn this array of notes/chords back into a MIDI? That’s where music21 comes back into play! This library not only lets us transform MIDI into an array, it lets us transform an array back into a MIDI!"
      ],
      "metadata": {
        "id": "3mpGFOypmOMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_midi(prediction_output):\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "#\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='output.mid')"
      ],
      "metadata": {
        "id": "aE5YryTNmV7J"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And there we have our prediction output as a MIDI! Now you just have to import it to your DAW and see what it sounds like! I recommend we should fine tune the model and play around with it to see what we can produce. I added some ambient noises and drums to one of the predictions, here are the results:"
      ],
      "metadata": {
        "id": "uayPxsQgmm_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from music21 import note, chord, stream, instrument\n",
        "\n",
        "def create_midi(prediction_output, output_file='/content/drive/MyDrive/Songs/output'):\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # Create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        pattern_str = str(pattern)  # Convert pattern to string\n",
        "\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern_str) or pattern_str.isdigit():\n",
        "            notes_in_chord = pattern_str.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(int(pattern))\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # Increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp=output_file)\n",
        "\n",
        "# Define the path where you want to save the MIDI file\n",
        "output_file_path = '/content/drive/MyDrive/Songs/output/output.mid'\n",
        "\n",
        "# Call the function to create and save the MIDI file\n",
        "create_midi(prediction_output, output_file_path)\n"
      ],
      "metadata": {
        "id": "pXXBcugOpLdz"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9llLjzflpPfM",
        "outputId": "86e4b4b4-d2b5-418c-e5c8-d377c31252e3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    }
  ]
}